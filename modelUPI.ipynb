{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc3943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10e0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6723f921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 0.2139\n",
      "Epoch 2/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0792\n",
      "Epoch 3/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0503\n",
      "Epoch 4/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0252\n",
      "Epoch 5/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0136\n",
      "Epoch 6/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0090\n",
      "Epoch 7/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0062\n",
      "Epoch 8/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0042\n",
      "Epoch 9/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024\n",
      "Epoch 10/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013\n",
      "Epoch 11/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011\n",
      "Epoch 12/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9335e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.9192e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.0354e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.6021e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.5585e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.8312e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.0504e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.6584e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6591e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.5263e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3989e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.2897e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.2003e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1827e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.1589e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2485e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1020e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1824e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0928e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.0318e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.1037e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 9.8379e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 9.5912e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.7540e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0567e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.4837e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.7060e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.7884e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.6134e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.8754e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.6908e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.2545e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.1709e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.9989e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.5771e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.5564e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5750e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.0487e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.8449e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.7169e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.0943e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.7714e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.2552e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.4739e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.3002e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.0216e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.8812e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.8832e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.4299e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.8231e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.9745e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.7504e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.5327e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.2839e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.2868e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.9760e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.5528e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1322e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.8777e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0067e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.9440e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.7549e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.2740e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.2067e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 4.6856e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.2428e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.4932e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.0030e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1574e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.4238e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.5755e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.8848e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.1351e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.4727e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 4.5932e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0322e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.7596e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 3.8518e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.9545e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.4762e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.5208e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 3.4295e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.4823e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.3095e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.1771e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.2450e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.2364e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2834e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.1965e-05\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step\n",
      "\n",
      "🔍 Best Threshold (F1 Optimized): 0.000000, Best F1: 0.5052\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     33106\n",
      "           1       0.34      1.00      0.51     16894\n",
      "\n",
      "    accuracy                           0.34     50000\n",
      "   macro avg       0.67      0.50      0.25     50000\n",
      "weighted avg       0.78      0.34      0.17     50000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   17 33089]\n",
      " [    0 16894]]\n",
      "ROC AUC Score: 0.7507539897297866\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('synthetic_upi_transactions.csv', parse_dates=['Timestamp'])\n",
    "df.sort_values(by='Timestamp', inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "df['TimeSinceLastTX'] = df.groupby('Sender UPI ID')['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "df['AvgAmountSender'] = df.groupby('Sender UPI ID')['Amount (INR)'].transform('mean')\n",
    "df['AvgAmountDevice'] = df.groupby('Device ID')['Amount (INR)'].transform('mean')\n",
    "df['Note'] = df['Note'].fillna('')\n",
    "note_counts = df['Note'].value_counts().to_dict()\n",
    "df['NoteFreq'] = df['Note'].map(note_counts)\n",
    "\n",
    "# One-hot encode Transaction Type\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "trans_type_ohe = ohe.fit_transform(df[['Transaction Type']])\n",
    "trans_type_df = pd.DataFrame(trans_type_ohe, columns=ohe.get_feature_names_out(['Transaction Type']))\n",
    "df = pd.concat([df.reset_index(drop=True), trans_type_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop leaked/irrelevant columns\n",
    "df.drop(columns=[\n",
    "    'Transaction ID', 'Timestamp', 'Sender Name', 'Receiver Name',\n",
    "    'Sender UPI ID', 'Receiver UPI ID', 'Note',\n",
    "    'Device Type', 'Device ID', 'Transaction Type'\n",
    "], inplace=True)\n",
    "\n",
    "# Label and feature separation\n",
    "labels = df['Fraud']\n",
    "features = df.drop(columns=['Fraud'])\n",
    "\n",
    "# Sanity check\n",
    "assert not features.isnull().any().any(), \"NaN detected\"\n",
    "assert np.isfinite(features.values).all(), \"Inf/-Inf detected\"\n",
    "\n",
    "# Remove constant features\n",
    "features = pd.DataFrame(VarianceThreshold(0.0).fit_transform(features))\n",
    "\n",
    "# Scaling\n",
    "features = features.clip(lower=-1e3, upper=1e3)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split data\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_scaled, labels, test_size=0.5, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Only train on normal (genuine) transactions\n",
    "X_train = X_train_full[y_train_full == 0]\n",
    "\n",
    "# Autoencoder Model\n",
    "input_dim = X_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "\n",
    "# Train\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "autoencoder.fit(X_train, X_train, \n",
    "                epochs=100, batch_size=256, \n",
    "                shuffle=True, verbose=1, \n",
    "                callbacks=[early_stop])\n",
    "\n",
    "# Inference\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)\n",
    "\n",
    "# Optimal Threshold via F1 Score\n",
    "best_thresh, best_f1 = 0, 0\n",
    "for t in np.linspace(min(mse), max(mse), 200):\n",
    "    preds = (mse > t).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\n🔍 Best Threshold (F1 Optimized): {best_thresh:.6f}, Best F1: {best_f1:.4f}\")\n",
    "\n",
    "# Final Prediction\n",
    "y_pred = (mse > best_thresh).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n📊 Evaluation Metrics:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c3e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.9420\n",
      "Epoch 2/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4901\n",
      "Epoch 3/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1392\n",
      "Epoch 4/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0461\n",
      "Epoch 5/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0364\n",
      "Epoch 6/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0154\n",
      "Epoch 7/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0035\n",
      "Epoch 8/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0025\n",
      "Epoch 9/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0020\n",
      "Epoch 10/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0018\n",
      "Epoch 11/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0013\n",
      "Epoch 12/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012\n",
      "Epoch 13/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012\n",
      "Epoch 14/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.2903e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.4223e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.5759e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.8153e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.5215e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.3988e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.5678e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.7392e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.3105e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.4591e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.1476e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 4.9147e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.2344e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.0528e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5479e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.8998e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.4565e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.5981e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2866e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.4838e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.1295e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.7509e-04\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step\n",
      "\n",
      "🔍 Best Threshold (F1 Optimized): 0.002499, Best F1: 0.7589\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     33106\n",
      "           1       1.00      0.61      0.76     16894\n",
      "\n",
      "    accuracy                           0.87     50000\n",
      "   macro avg       0.92      0.81      0.83     50000\n",
      "weighted avg       0.89      0.87      0.86     50000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[33069    37]\n",
      " [ 6541 10353]]\n",
      "ROC AUC Score: 0.9222159326917378\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('synthetic_upi_transactions.csv', parse_dates=['Timestamp'])\n",
    "df.sort_values(by='Timestamp', inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['TimeSinceLastTX'] = df.groupby('Sender UPI ID')['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "df['AvgAmountSender'] = df.groupby('Sender UPI ID')['Amount (INR)'].transform('mean')\n",
    "df['AvgAmountDevice'] = df.groupby('Device ID')['Amount (INR)'].transform('mean')\n",
    "df['Note'] = df['Note'].fillna('')\n",
    "note_counts = df['Note'].value_counts().to_dict()\n",
    "df['NoteFreq'] = df['Note'].map(note_counts)\n",
    "\n",
    "# One-hot encode Transaction Type\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "trans_type_ohe = ohe.fit_transform(df[['Transaction Type']])\n",
    "trans_type_df = pd.DataFrame(trans_type_ohe, columns=ohe.get_feature_names_out(['Transaction Type']))\n",
    "df = pd.concat([df.reset_index(drop=True), trans_type_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop irrelevant/leaking columns\n",
    "df.drop(columns=[\n",
    "    'Transaction ID', 'Timestamp', 'Sender Name', 'Receiver Name',\n",
    "    'Sender UPI ID', 'Receiver UPI ID', 'Note',\n",
    "    'Device Type', 'Device ID', 'Transaction Type'\n",
    "], inplace=True)\n",
    "\n",
    "# Labels and features\n",
    "labels = df['Fraud']\n",
    "features = df.drop(columns=['Fraud'])\n",
    "\n",
    "# Clean features\n",
    "assert not features.isnull().any().any()\n",
    "assert np.isfinite(features.values).all()\n",
    "\n",
    "# Remove constant features\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "features = pd.DataFrame(vt.fit_transform(features))\n",
    "\n",
    "# Use Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split dataset\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_scaled, labels, test_size=0.5, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Only train on normal data (non-fraud)\n",
    "X_train = X_train_full[y_train_full == 0]\n",
    "\n",
    "# Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "output_layer = Dense(input_dim, activation='linear')(decoded)  # Linear activation here\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "\n",
    "# Train\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "autoencoder.fit(X_train, X_train, \n",
    "                epochs=100, batch_size=256, \n",
    "                shuffle=True, verbose=1, \n",
    "                callbacks=[early_stop])\n",
    "\n",
    "# Predict reconstruction error\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.square(X_test - reconstructions), axis=1)\n",
    "\n",
    "# Tune threshold for best F1\n",
    "best_thresh, best_f1 = 0, 0\n",
    "for t in np.linspace(np.percentile(mse, 50), np.percentile(mse, 99.9), 200):\n",
    "    preds = (mse > t).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\n🔍 Best Threshold (F1 Optimized): {best_thresh:.6f}, Best F1: {best_f1:.4f}\")\n",
    "\n",
    "# Final prediction\n",
    "y_pred = (mse > best_thresh).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n📊 Evaluation Metrics:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ecc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Best Threshold (F1 Optimized): 0.000859, Best F1: 0.5782\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86     33106\n",
      "           1       0.91      0.42      0.58     16894\n",
      "\n",
      "    accuracy                           0.79     50000\n",
      "   macro avg       0.84      0.70      0.72     50000\n",
      "weighted avg       0.82      0.79      0.77     50000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[32373   733]\n",
      " [ 9726  7168]]\n",
      "ROC AUC Score: 0.8038116724141992\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv('synthetic_upi_transactions.csv', parse_dates=['Timestamp'])\n",
    "df.sort_values(by='Timestamp', inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['TimeSinceLastTX'] = df.groupby('Sender UPI ID')['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "df['AvgAmountSender'] = df.groupby('Sender UPI ID')['Amount (INR)'].transform('mean')\n",
    "df['AvgAmountDevice'] = df.groupby('Device ID')['Amount (INR)'].transform('mean')\n",
    "df['Note'] = df['Note'].fillna('')\n",
    "df['NoteFreq'] = df['Note'].map(df['Note'].value_counts().to_dict())\n",
    "\n",
    "# One-hot encode Transaction Type\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "trans_type_df = pd.DataFrame(ohe.fit_transform(df[['Transaction Type']]), \n",
    "                             columns=ohe.get_feature_names_out(['Transaction Type']))\n",
    "df = pd.concat([df.reset_index(drop=True), trans_type_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop irrelevant or leaked features\n",
    "drop_cols = ['Transaction ID', 'Timestamp', 'Sender Name', 'Receiver Name',\n",
    "             'Sender UPI ID', 'Receiver UPI ID', 'Note',\n",
    "             'Device Type', 'Device ID', 'Transaction Type']\n",
    "df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Separate label\n",
    "labels = df['Fraud']\n",
    "features = df.drop(columns=['Fraud'])\n",
    "\n",
    "# Remove constant features\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "features = pd.DataFrame(vt.fit_transform(features), columns=features.columns[vt.get_support()])\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# SMOTE to balance classes (only for evaluation, not for training autoencoders)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_scaled, labels, test_size=0.5, random_state=42, stratify=labels)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_train_full, y_train_full)\n",
    "\n",
    "# Use only genuine transactions to train each autoencoder\n",
    "X_train_genuine = X_train_full[y_train_full == 0]\n",
    "\n",
    "# Autoencoder builder\n",
    "def build_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    encoded = Dense(16, activation='relu')(encoded)\n",
    "    decoded = Dense(32, activation='relu')(encoded)\n",
    "    decoded = Dense(64, activation='relu')(decoded)\n",
    "    output_layer = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train multiple autoencoders\n",
    "n_autoencoders = 3\n",
    "autoencoders = []\n",
    "for i in range(n_autoencoders):\n",
    "    ae = build_autoencoder(X_train_genuine.shape[1])\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    ae.fit(X_train_genuine, X_train_genuine,\n",
    "           epochs=50, batch_size=128, verbose=0, shuffle=True,\n",
    "           callbacks=[early_stop])\n",
    "    autoencoders.append(ae)\n",
    "\n",
    "# Average reconstruction error across all autoencoders\n",
    "reconstruction_errors = np.zeros(len(X_test))\n",
    "for ae in autoencoders:\n",
    "    recon = ae.predict(X_test, verbose=0)\n",
    "    error = np.mean(np.square(X_test - recon), axis=1)\n",
    "    reconstruction_errors += error\n",
    "reconstruction_errors /= n_autoencoders\n",
    "\n",
    "# Optimal threshold via F1-score\n",
    "best_thresh, best_f1 = 0, 0\n",
    "for t in np.linspace(min(reconstruction_errors), max(reconstruction_errors), 100):\n",
    "    preds = (reconstruction_errors > t).astype(int)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\n🔍 Best Threshold (F1 Optimized): {best_thresh:.6f}, Best F1: {best_f1:.4f}\")\n",
    "\n",
    "# Final predictions\n",
    "final_preds = (reconstruction_errors > best_thresh).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n📊 Evaluation Metrics:\")\n",
    "print(classification_report(y_test, final_preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, final_preds))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, reconstruction_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1958fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944us/step\n",
      "\n",
      "🔍 Best Threshold (F1 Optimized using PR Curve): 0.000422\n",
      "📈 Precision-Recall AUC: 0.9076, Best F1: 0.8065\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90     33106\n",
      "           1       0.82      0.79      0.81     16894\n",
      "\n",
      "    accuracy                           0.87     50000\n",
      "   macro avg       0.86      0.85      0.85     50000\n",
      "weighted avg       0.87      0.87      0.87     50000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30140  2966]\n",
      " [ 3474 13420]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('synthetic_upi_transactions.csv', parse_dates=['Timestamp'])\n",
    "df.sort_values(by='Timestamp', inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['TimeSinceLastTX'] = df.groupby('Sender UPI ID')['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "df['AvgAmountSender'] = df.groupby('Sender UPI ID')['Amount (INR)'].transform('mean')\n",
    "df['AvgAmountDevice'] = df.groupby('Device ID')['Amount (INR)'].transform('mean')\n",
    "df['Note'] = df['Note'].fillna('')\n",
    "note_counts = df['Note'].value_counts().to_dict()\n",
    "df['NoteFreq'] = df['Note'].map(note_counts)\n",
    "\n",
    "# One-hot encode Transaction Type\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "trans_type_ohe = ohe.fit_transform(df[['Transaction Type']])\n",
    "trans_type_df = pd.DataFrame(trans_type_ohe, columns=ohe.get_feature_names_out(['Transaction Type']))\n",
    "df = pd.concat([df.reset_index(drop=True), trans_type_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop irrelevant/leaking columns\n",
    "df.drop(columns=[\n",
    "    'Transaction ID', 'Timestamp', 'Sender Name', 'Receiver Name',\n",
    "    'Sender UPI ID', 'Receiver UPI ID', 'Note',\n",
    "    'Device Type', 'Device ID', 'Transaction Type'\n",
    "], inplace=True)\n",
    "\n",
    "# Labels and features\n",
    "labels = df['Fraud']\n",
    "features = df.drop(columns=['Fraud'])\n",
    "\n",
    "# Clean and scale features\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "features = pd.DataFrame(vt.fit_transform(features))\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split into test and rest\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(\n",
    "    X_scaled, labels, test_size=0.5, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Use only genuine data for training\n",
    "X_rest = X_rest[y_rest == 0]\n",
    "\n",
    "# Function to create autoencoder\n",
    "def create_autoencoder(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    x = Dense(128, activation='relu')(inp)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(input_dim, activation='linear')(x)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer=Adam(1e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train multiple autoencoders on bootstrapped samples\n",
    "n_models = 3\n",
    "input_dim = X_rest.shape[1]\n",
    "models = []\n",
    "recon_errors = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    # Bootstrap sample from normal data\n",
    "    idx = np.random.choice(len(X_rest), len(X_rest), replace=True)\n",
    "    X_boot = X_rest[idx]\n",
    "\n",
    "    model = create_autoencoder(input_dim)\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_boot, X_boot, epochs=100, batch_size=256, verbose=0, callbacks=[early_stop])\n",
    "    \n",
    "    # Predict reconstruction error on test\n",
    "    pred = model.predict(X_test)\n",
    "    err = np.mean(np.square(X_test - pred), axis=1)\n",
    "    recon_errors.append(err)\n",
    "    models.append(model)\n",
    "\n",
    "# Average reconstruction error\n",
    "avg_error = np.mean(recon_errors, axis=0)\n",
    "\n",
    "# Precision-Recall AUC optimization\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, avg_error)\n",
    "pr_au_score = auc(recalls, precisions)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "best_f1_index = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[best_f1_index]\n",
    "best_f1 = f1_scores[best_f1_index]\n",
    "\n",
    "# Final predictions\n",
    "y_pred = (avg_error > best_thresh).astype(int)\n",
    "\n",
    "# Results\n",
    "print(f\"\\n🔍 Best Threshold (F1 Optimized using PR Curve): {best_thresh:.6f}\")\n",
    "print(f\"📈 Precision-Recall AUC: {pr_au_score:.4f}, Best F1: {best_f1:.4f}\")\n",
    "print(\"\\n📊 Evaluation Metrics:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, reconstruction_errors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae24666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\n",
      "🔍 Best Threshold (F1 Optimized using PR Curve): 0.000927\n",
      "📈 Precision-Recall AUC: 0.8687, Best F1: 0.7685\n",
      "\n",
      "📊 Evaluation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90     33106\n",
      "           1       0.90      0.67      0.77     16894\n",
      "\n",
      "    accuracy                           0.86     50000\n",
      "   macro avg       0.88      0.82      0.84     50000\n",
      "weighted avg       0.87      0.86      0.86     50000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[31902  1204]\n",
      " [ 5602 11292]]\n",
      "ROC AUC Score: 0.8038116724141992\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load and sort data\n",
    "df = pd.read_csv('synthetic_upi_transactions.csv', parse_dates=['Timestamp'])\n",
    "df.sort_values(by='Timestamp', inplace=True)\n",
    "\n",
    "# === FEATURE ENGINEERING ===\n",
    "\n",
    "# Time since last transaction (per user)\n",
    "df['TimeSinceLastTX'] = df.groupby('Sender UPI ID')['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "# Hour of transaction\n",
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "\n",
    "# Average and Std of amount sent by user (risk profiling)\n",
    "df['AvgAmountSender'] = df.groupby('Sender UPI ID')['Amount (INR)'].transform('mean')\n",
    "df['StdAmountSender'] = df.groupby('Sender UPI ID')['Amount (INR)'].transform('std').fillna(0)\n",
    "\n",
    "# Average amount sent from device\n",
    "df['AvgAmountDevice'] = df.groupby('Device ID')['Amount (INR)'].transform('mean')\n",
    "\n",
    "# Note frequency\n",
    "df['Note'] = df['Note'].fillna('')\n",
    "note_counts = df['Note'].value_counts().to_dict()\n",
    "df['NoteFreq'] = df['Note'].map(note_counts)\n",
    "\n",
    "# === Transaction Velocity (per user in rolling 1.5 hour window) ===\n",
    "# df = df.set_index('Timestamp')\n",
    "\n",
    "df['TXCount_1_5hr'] = (\n",
    "    df.groupby('Sender UPI ID')['Sender UPI ID']\n",
    "      .rolling(5400)\n",
    "      .count()\n",
    "      .reset_index(level=0, drop=True)\n",
    "      .fillna(1)\n",
    ")\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# One-hot encode Transaction Type\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "trans_type_ohe = ohe.fit_transform(df[['Transaction Type']])\n",
    "trans_type_df = pd.DataFrame(trans_type_ohe, columns=ohe.get_feature_names_out(['Transaction Type']))\n",
    "df = pd.concat([df.reset_index(drop=True), trans_type_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop irrelevant/leaking columns\n",
    "df.drop(columns=[\n",
    "    'Transaction ID', 'Timestamp', 'Sender Name', 'Receiver Name',\n",
    "    'Sender UPI ID', 'Receiver UPI ID', 'Note',\n",
    "    'Device Type', 'Device ID', 'Transaction Type'\n",
    "], inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "labels = df['Fraud']\n",
    "features = df.drop(columns=['Fraud'])\n",
    "\n",
    "# Clean and scale features\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "features = pd.DataFrame(vt.fit_transform(features))\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split into test and rest\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(\n",
    "    X_scaled, labels, test_size=0.5, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Use only genuine transactions for training\n",
    "X_rest = X_rest[y_rest == 0]\n",
    "\n",
    "# === AUTOENCODER WITH L1 REGULARIZATION ===\n",
    "def create_autoencoder(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    x = Dense(128, activation='relu', activity_regularizer=regularizers.l1(1e-5))(inp)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(input_dim, activation='linear')(x)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer=Adam(1e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train multiple autoencoders on bootstrapped samples\n",
    "n_models = 4\n",
    "input_dim = X_rest.shape[1]\n",
    "models = []\n",
    "recon_errors = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    idx = np.random.choice(len(X_rest), len(X_rest), replace=True)\n",
    "    X_boot = X_rest[idx]\n",
    "\n",
    "    model = create_autoencoder(input_dim)\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_boot, X_boot, epochs=100, batch_size=256, verbose=0, callbacks=[early_stop])\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    err = np.mean(np.square(X_test - pred), axis=1)\n",
    "    recon_errors.append(err)\n",
    "    models.append(model)\n",
    "\n",
    "# Average reconstruction error\n",
    "avg_error = np.mean(recon_errors, axis=0)\n",
    "\n",
    "# Precision-Recall AUC optimization\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, avg_error)\n",
    "pr_au_score = auc(recalls, precisions)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "best_f1_index = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[best_f1_index]\n",
    "best_f1 = f1_scores[best_f1_index]\n",
    "\n",
    "# Final predictions\n",
    "y_pred = (avg_error > best_thresh).astype(int)\n",
    "\n",
    "# === RESULTS ===\n",
    "print(f\"\\n🔍 Best Threshold (F1 Optimized using PR Curve): {best_thresh:.6f}\")\n",
    "print(f\"📈 Precision-Recall AUC: {pr_au_score:.4f}, Best F1: {best_f1:.4f}\")\n",
    "print(\"\\n📊 Evaluation Metrics:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, reconstruction_errors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76001e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 927us/step\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972us/step\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\n",
      "🔍 Best Threshold (F1 Optimized): 0.000168\n",
      "📈 PR AUC: 0.9107, Best F1: 0.8066\n",
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     52969\n",
      "           1       0.80      0.81      0.81     27031\n",
      "\n",
      "    accuracy                           0.87     80000\n",
      "   macro avg       0.85      0.85      0.85     80000\n",
      "weighted avg       0.87      0.87      0.87     80000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[47663  5306]\n",
      " [ 5176 21855]]\n",
      "ROC AUC Score: 0.9375393565715758\n",
      "Saved ensemble model as 'final_fraud_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "import pickle   \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, auc, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('synthetic_upi_transactions.csv', parse_dates=['Timestamp'])\n",
    "df.sort_values(by='Timestamp', inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['TimeSinceLastTX'] = df.groupby('Sender UPI ID')['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "df['Hour'] = df['Timestamp'].dt.hour\n",
    "df['AvgAmountSender'] = df.groupby('Sender UPI ID')['Amount (INR)'].transform('mean')\n",
    "df['AvgAmountDevice'] = df.groupby('Device ID')['Amount (INR)'].transform('mean')\n",
    "df['Note'] = df['Note'].fillna('')\n",
    "note_counts = df['Note'].value_counts().to_dict()\n",
    "df['NoteFreq'] = df['Note'].map(note_counts)\n",
    "\n",
    "# One-hot encode Transaction Type\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "trans_type_ohe = ohe.fit_transform(df[['Transaction Type']])\n",
    "trans_type_df = pd.DataFrame(trans_type_ohe, columns=ohe.get_feature_names_out(['Transaction Type']))\n",
    "df = pd.concat([df.reset_index(drop=True), trans_type_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop irrelevant/leaking columns\n",
    "df.drop(columns=[\n",
    "    'Transaction ID', 'Timestamp', 'Sender Name', 'Receiver Name',\n",
    "    'Sender UPI ID', 'Receiver UPI ID', 'Note',\n",
    "    'Device Type', 'Device ID', 'Transaction Type'\n",
    "], inplace=True)\n",
    "\n",
    "# Labels and features\n",
    "labels = df['Fraud']\n",
    "features = df.drop(columns=['Fraud'])\n",
    "\n",
    "# Feature selection and scaling\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "features = pd.DataFrame(vt.fit_transform(features))\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Train/test split\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(\n",
    "    X_scaled, labels, test_size=0.8, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Use only genuine transactions for training\n",
    "X_rest = X_rest[y_rest == 0]\n",
    "\n",
    "# Autoencoder architecture\n",
    "def create_autoencoder(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    x = Dense(128, activation='relu')(inp)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    out = Dense(input_dim, activation='linear')(x)\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer=Adam(1e-4), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train multiple autoencoders\n",
    "n_models = 3\n",
    "input_dim = X_rest.shape[1]\n",
    "models = []\n",
    "recon_errors = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    idx = np.random.choice(len(X_rest), len(X_rest), replace=True)\n",
    "    X_boot = X_rest[idx]\n",
    "\n",
    "    model = create_autoencoder(input_dim)\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    model.fit(X_boot, X_boot, epochs=100, batch_size=256, verbose=0, callbacks=[early_stop])\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    err = np.mean(np.square(X_test - pred), axis=1)\n",
    "    recon_errors.append(err)\n",
    "    models.append(model)\n",
    "\n",
    "# Average reconstruction error\n",
    "avg_error = np.mean(recon_errors, axis=0)\n",
    "\n",
    "# Precision-Recall AUC optimization\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, avg_error)\n",
    "pr_au_score = auc(recalls, precisions)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "best_f1_index = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[best_f1_index]\n",
    "best_f1 = f1_scores[best_f1_index]\n",
    "\n",
    "# Final predictions\n",
    "y_pred = (avg_error > best_thresh).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"\\n🔍 Best Threshold (F1 Optimized): {best_thresh:.6f}\")\n",
    "print(f\"📈 PR AUC: {pr_au_score:.4f}, Best F1: {best_f1:.4f}\")\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, avg_error))\n",
    "\n",
    "# ---- Save complete model ----\n",
    "class FraudDetectionEnsemble:\n",
    "    def __init__(self, models, scaler, vt, ohe, threshold):\n",
    "        self.models = models\n",
    "        self.scaler = scaler\n",
    "        self.vt = vt\n",
    "        self.ohe = ohe\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def predict(self, X_raw_df):\n",
    "        X = X_raw_df.copy()\n",
    "        X['TimeSinceLastTX'] = X.groupby('Sender UPI ID')['Timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "        X['Hour'] = X['Timestamp'].dt.hour\n",
    "        X['AvgAmountSender'] = X.groupby('Sender UPI ID')['Amount (INR)'].transform('mean')\n",
    "        X['AvgAmountDevice'] = X.groupby('Device ID')['Amount (INR)'].transform('mean')\n",
    "        X['Note'] = X['Note'].fillna('')\n",
    "        note_counts = X['Note'].value_counts().to_dict()\n",
    "        X['NoteFreq'] = X['Note'].map(note_counts)\n",
    "\n",
    "        trans_type_ohe = self.ohe.transform(X[['Transaction Type']])\n",
    "        trans_type_df = pd.DataFrame(trans_type_ohe, columns=self.ohe.get_feature_names_out(['Transaction Type']))\n",
    "        X = pd.concat([X.reset_index(drop=True), trans_type_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        X.drop(columns=[\n",
    "            'Transaction ID', 'Timestamp', 'Sender Name', 'Receiver Name',\n",
    "            'Sender UPI ID', 'Receiver UPI ID', 'Note',\n",
    "            'Device Type', 'Device ID', 'Transaction Type'\n",
    "        ], inplace=True)\n",
    "\n",
    "        X = pd.DataFrame(self.vt.transform(X))\n",
    "        X = self.scaler.transform(X)\n",
    "\n",
    "        errors = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X)\n",
    "            err = np.mean(np.square(X - pred), axis=1)\n",
    "            errors.append(err)\n",
    "\n",
    "        avg_error = np.mean(errors, axis=0)\n",
    "        return (avg_error > self.threshold).astype(int), avg_error\n",
    "\n",
    "# Save final object\n",
    "ensemble_model = FraudDetectionEnsemble(models=models, scaler=scaler, vt=vt, ohe=ohe, threshold=best_thresh)\n",
    "with open('final_fraud_model.pkl', 'wb') as f:\n",
    "    pickle.dump(ensemble_model, f)\n",
    "print(\"Saved ensemble model as 'final_fraud_model.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
